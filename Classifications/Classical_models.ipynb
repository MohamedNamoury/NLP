{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Classical_models.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"9YJpXRE4sRNj","executionInfo":{"status":"ok","timestamp":1632838776668,"user_tz":-120,"elapsed":3901,"user":{"displayName":"Lamis Hassan","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07753791031170065343"}}},"source":["import pandas as pd\n","import nltk\n","import re\n","from tqdm import tqdm as tq\n","import spacy\n","\n","from sklearn import svm, preprocessing\n","from sklearn.metrics import classification_report, confusion_matrix , accuracy_score\n","from sklearn.feature_extraction.text import TfidfVectorizer , CountVectorizer, TfidfTransformer\n","from sklearn.model_selection import train_test_split\n","\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neighbors import KNeighborsClassifier"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"0J_2x_cQu3As","colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"status":"error","timestamp":1622333940356,"user_tz":-120,"elapsed":255,"user":{"displayName":"Lamis Hassan","photoUrl":"","userId":"07753791031170065343"}},"outputId":"43aa2561-47c3-4328-a52d-71782d89a719"},"source":["books_df = pd.read_csv('gutenberg_books_partitions.csv')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-8888956316ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbooks_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gutenberg_books_partitions.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gutenberg_books_partitions.csv'"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246},"id":"4CpgcHbu1FCs","executionInfo":{"status":"error","timestamp":1622334002000,"user_tz":-120,"elapsed":234,"user":{"displayName":"Lamis Hassan","photoUrl":"","userId":"07753791031170065343"}},"outputId":"6c629862-4eaf-4af1-f89e-68453a19435e"},"source":["tfidf_vec = TfidfVectorizer()\n","tfidf = tfidf_vec.fit_transform(books_df.partition.values)\n","\n","tfidf_vec_bigram = TfidfVectorizer(ngram_range=(2, 2))\n","tfidf_bigram = tfidf_vec_bigram.fit_transform(books_df.partition.values)\n","\n","bow_vec = CountVectorizer()\n","bow = bow_vec.fit_transform(books_df.partition.values)\n","print(bow.shape)\n","\n","bow_vec_bigram = CountVectorizer(ngram_range=(2,2))\n","bow_bigram = bow_vec_bigram.fit_transform(books_df.partition.values)\n"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-a73847d1c55c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtfidf_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfidf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooks_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtfidf_vec_bigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtfidf_bigram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vec_bigram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbooks_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'books_df' is not defined"]}]},{"cell_type":"code","metadata":{"id":"qxqYYcy9vg3A"},"source":["# Method contains all the classification algorithms\n","def estimators(features, labels, estimator):\n","  X_train, X_test, y_train, y_test = train_test_split(\n","     features, labels, test_size=0.2, random_state=0)\n","  if (estimator == 'SVM'):\n","    model = svm.SVC().fit(X_train, y_train )\n","    text = 'SVM'\n","  if (estimator == 'DecisionTree'):\n","    model = DecisionTreeClassifier().fit(X_train, y_train)\n","    text = 'Decision Tree'\n","  if (estimator == 'KNN'):\n","    model = KNeighborsClassifier(n_neighbors = 15).fit(X_train, y_train)\n","    text = 'KNN'\n","\n","  train_prediction = model.predict(X_train)\n","  prediction = model.predict(X_test)\n","  print(text, \" Train Accuracy : \", accuracy_score(y_train,train_prediction)*100)\n","  print(text, \" Test Accuracy : \", accuracy_score(y_test,prediction)*100)\n","  print(\"\\n\\t\\tTEST DATA METRICS\")\n","  print(text, \" Confusion Matrix: \",confusion_matrix(y_test, prediction))\n","  print(text, \" Report : \")\n","  print(classification_report(y_test,prediction))  \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AexnI0oUfN4t"},"source":["# Scoring and Prediction of different classifiers using TFiDF"]},{"cell_type":"code","metadata":{"id":"pYvDzYi_l56u"},"source":["#TFiDF\n","print('SVM on TFiDF')\n","estimators(tfidf, books_df.book_name.values, 'SVM')\n","\n","print('Decision Tree on TFiDF')\n","estimators(tfidf, books_df.book_name.values, 'DecisionTree')\n","\n","print('KNN on TFiDF')\n","estimators(tfidf, books_df.book_name.values, 'KNN')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"42HC3HFqxIN0"},"source":["# Scoring and Prediction of different classifiers using BOW "]},{"cell_type":"code","metadata":{"id":"SsPzSCDpo7IK"},"source":["# BOW\n","print('SVM on BOW')\n","estimators(bow , books_df.book_name.values, 'SVM')\n","\n","print('Decision Tree on BOW')\n","estimators(bow , books_df.book_name.values, 'DecisionTree')\n","\n","print('KNN on BOW')\n","estimators(bow , books_df.book_name.values, 'KNN')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jnFjWQb9xk28"},"source":["# Scoring and Prediction of different classifiers using n-grams\n","\n","*   We use n-grams in terms of TFiDF as the accuracy in TFiDF is better than the BOW \n","\n","\n","\n","\n","\n","\n","\n"," "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":264},"id":"6QD899zGxkh7","executionInfo":{"status":"error","timestamp":1622333987430,"user_tz":-120,"elapsed":328,"user":{"displayName":"Lamis Hassan","photoUrl":"","userId":"07753791031170065343"}},"outputId":"2c733c2d-2ed3-45a2-831a-4a14278e0412"},"source":["# n-grams\n","# tfidf_bigram\n","print('SVM on n-grams')\n","estimators(tfidf_bigram, books_df.book_name.values, 'SVM')\n","\n","print('Decision Tree on n-grams')\n","estimators(tfidf_bigram , books_df.book_name.values, 'DecisionTree')\n","\n","print('KNN on n-grams')\n","estimators(tfidf_bigram , books_df.book_name.values, 'KNN')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["SVM on n-grams\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-42dc44788f2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# tfidf_bigram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SVM on n-grams'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mestimators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_bigram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbooks_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SVM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Decision Tree on n-grams'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'estimators' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"HWJmmfpfLApt"},"source":["# Cross Validation Method"]},{"cell_type":"code","metadata":{"id":"FahV6OqBOQcU"},"source":["from sklearn.model_selection import KFold, cross_val_score\n","from numpy import mean\n","from numpy import std"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-lsTcH7xN4vs"},"source":["def cross_validation(features, labels, estimator):\n","  cv = KFold(n_splits=10, random_state=1, shuffle=True)\n","  if (estimator == 'SVM'):\n","    model = svm.SVC()\n","  if (estimator == 'DecisionTree'):\n","    model = DecisionTreeClassifier()\n","  if (estimator == 'KNN'):\n","    model = KNeighborsClassifier(n_neighbors=15)\n","\n","  scores = cross_val_score(model, features, labels, scoring='accuracy', cv=cv)\n","  print('Accuracy: ',  mean(scores))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNw530nOxbju"},"source":["#TFiDF\n","print('Cross Validation SVM on TFiDF')\n","cross_validation(tfidf, books_df.book_name.values, 'SVM')\n","\n","print('\\n')\n","\n","print('Cross Validation Decision Tree on TFiDF')\n","cross_validation(tfidf, books_df.book_name.values, 'DecisionTree')\n","print('\\n')\n","\n","print('Cross Validation KNN on TFiDF')\n","cross_validation(tfidf, books_df.book_name.values, 'KNN') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pw2tW6USRmod"},"source":["# BOW\n","print('Cross Validation SVM on BOW')\n","cross_validation(bow , books_df.book_name.values, 'SVM')\n","print('\\n')\n","\n","print('Cross Validation Decision Tree on BOW')\n","cross_validation(bow , books_df.book_name.values, 'DecisionTree')\n","print('\\n')\n","\n","print('Cross Validation KNN on BOW')\n","cross_validation(bow , books_df.book_name.values, 'KNN')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rlw2-mgNUtkJ"},"source":["# n-grams\n","# tfidf_bigram\n","print('SVM on n-grams')\n","cross_validation(tfidf_bigram, books_df.book_name.values, 'SVM')\n","print('\\n')\n","\n","print('Decision Tree on n-grams')\n","cross_validation(tfidf_bigram , books_df.book_name.values, 'DecisionTree')\n","print('\\n')\n","\n","print('KNN on n-grams')\n","cross_validation(tfidf_bigram , books_df.book_name.values, 'KNN')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3q-pHS6BLTYB"},"source":["## Using LDA Models\n"]},{"cell_type":"code","metadata":{"id":"wtS0jxRpLY3M"},"source":["# !pip install pyLDAvis"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WG8IfroGLZUI"},"source":["import gensim\n","import gensim.corpora as corpora\n","from gensim.utils import simple_preprocess\n","from gensim.models import CoherenceModel\n","import numpy as np\n","\n","# import pyLDAvis\n","# import pyLDAvis.gensim_models as gensimvis\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNfPz3JHPqga"},"source":["nltk.download('stopwords')\n","nltk.download('gutenberg')\n","nltk.download('punkt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LRxnHX_vtF5"},"source":["lda_corpus=[]\n","lda_corpus_sent=[]\n","for part in books_df.partition:\n","  lda_corpus_sent.append([part])\n","  lda_corpus.append([w for w in nltk.word_tokenize(part.lower())])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o9DcOcIWekiX"},"source":["**Feature Extraction**"]},{"cell_type":"code","metadata":{"id":"nGPRaZYy35DP"},"source":["id2word = corpora.Dictionary(lda_corpus)\n","print(id2word)\n","texts = lda_corpus\n","corpus = [id2word.doc2bow(text) for text in texts]\n","# Term Document Frequency\n","#bow_vec = CountVectorizer()\n","#bow = bow_vec.fit_transform(books_df.partition.values)\n","#corpus = [bow_vec.transform(text) for text in texts]\n","id2wordsen = corpora.Dictionary(lda_corpus_sent)\n","texts = lda_corpus\n","corpus_sent = [id2word.doc2bow(text) for text in texts]\n","print(id2wordsen)\n","\n","# View\n","print(len(corpus))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gJwnvCjX81ym"},"source":["lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus_sent,\n","                                          id2word=id2word,\n","                                           num_topics=20, \n","                                           random_state=100,\n","                                           update_every=1,\n","                                           chunksize=100,\n","                                           passes=10,\n","                                           alpha='auto',\n","                                    per_word_topics=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hIT4G5N9yq3G"},"source":["for idx, topic in lda_model.print_topics(-1):\n","    print('Topic: {} \\nWords: {}'.format(idx, topic))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"86ywinNx6l6X"},"source":["***Making vector out of the LDA model to use them as input for the supervised classifer***"]},{"cell_type":"code","metadata":{"id":"rJEAT8J7-Y8N"},"source":["train_vecs = []\n","for i in range(len(books_df.partition)):\n","    top_topics = lda_model.get_document_topics(corpus_sent[i], minimum_probability=0.0)\n","    topic_vec = [top_topics[i][1] for i in range(20)]\n","    train_vecs.append(topic_vec)                      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j53U2yXNo4XZ"},"source":["train_vecs[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"juyZVizT6dvM"},"source":["X  = np.array(train_vecs)\n","print(X.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_JzgJNon64el"},"source":["y = np.array(books_df.book_name)\n","len(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgenUFZkQpna"},"source":["#TFiDF\n","print('Cross Validation SVM on LDA')\n","cross_validation(X, y, 'SVM')\n","print('\\n')\n","\n","print('Cross Validation Decision Tree on LDA')\n","cross_validation(X, y, 'DecisionTree')\n","print('\\n')\n","\n","print('Cross Validation KNN on LDA')\n","cross_validation(X, y, 'KNN') "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wfsbDvfD_2C2"},"source":["# Visualization"]},{"cell_type":"code","metadata":{"id":"zoiiQs7yiHtB"},"source":["import matplotlib.pyplot as plt\n","from wordcloud import WordCloud"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A2kXCKr2iMAU"},"source":["# text is the input to the generate() method\n","wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='white', collocations=False).generate(''.join(books_df.partition.values.tolist()))\n","#draw the figure\n","#Set figure size\n","plt.figure(figsize=(20, 20))\n","# Display image\n","plt.imshow(wordcloud) \n","# No axis \n","plt.axis(\"off\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fvIFaQUc3uzv"},"source":[""],"execution_count":null,"outputs":[]}]}